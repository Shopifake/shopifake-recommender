docker build -t fastapi-template .
docker run -d -p 8000:8000 \
# Shopifake Recommender

FastAPI microservice powering the future RAG-based recommendation engine for Shopifake. For now it exposes a contract that the catalog service can call when a product is created or updated and logs the payload for downstream processing.

## üöÄ Features

- FastAPI 0.116.2 served through Gunicorn+Uvicorn workers
- Qdrant health monitoring to validate the vector store dependency
- Product registration endpoint with strict Pydantic schemas and an in-memory registry
- Redis-backed embedding ingestion API that pushes jobs onto a worker queue
- Streaming embedding worker that syncs vectors into Qdrant with optional deletes
- Debug-only decoder and encoder routes to validate LLM + embedding credentials
- End-to-end tests (pytest + httpx async fixtures)
- Ruff + Black enforced via CI workflows

## üèÉ Quick Start

```bash
cp .env.example.dev .env
# Fill in OPENAI_API_KEY plus the decoder (`OPENAI_MODEL`) and encoder (`OPENAI_EMBEDDING_MODEL`) names
pip install -r requirements.txt
uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload
python -m src.services.embedding_worker  # runs the async embedding worker
```

Or spin up the full stack (app + Qdrant):

```bash
docker compose up -d --build
```

The compose file now starts FastAPI, Qdrant, Redis, the embedding worker, and the static UI container.

API surface:

- `GET /` ‚Äì Basic heartbeat
- `GET /health` ‚Äì Reports app status + Qdrant connectivity
- `POST /products/register` ‚Äì Primary contract used by the catalog service
- `POST /v1/embeddings` ‚Äì Asynchronously enqueue embedding jobs (returns 202)
- `POST /debug/decoder` ‚Äì Fire a completion against the configured decoder (non-prod)
- `POST /debug/encoder` ‚Äì Generate embeddings against the configured encoder (non-prod)

See autogenerated docs at http://localhost:8000/docs

## üì¶ Product registration contract

```json
{
  "product_id": "string",
  "site_id": "string",
  "name": "string",
  "description": "string",
  "images": ["https://..."],
  "categories": [{"id": "string", "site_id": "string", "name": "string"}],
  "sku": "string",
  "status": "PUBLISHED",
  "price": 199.99,
  "filters": [{"id": "string", "name": "string", "value": "string"}],
  "metadata": {}
}
```

The endpoint stores the payload in an in-memory registry, timestamps it, logs the JSON body, and echoes it back to the caller. The catalog service will call this route for every publish event.

## üß™ Development Commands

```bash
pytest
ruff check src tests
black src tests
```

## üóÇÔ∏è Project highlights

```
src/
‚îú‚îÄ‚îÄ main.py              # FastAPI setup and routing
‚îú‚îÄ‚îÄ config.py            # Environment + Qdrant settings
‚îú‚îÄ‚îÄ models/product.py    # Pydantic schemas for incoming payloads
‚îî‚îÄ‚îÄ services/
    ‚îî‚îÄ‚îÄ product_registry.py  # In-memory storage + dependency provider
```

`tests/` contains API-level tests that exercise the new registration flow.

## üßµ Embedding pipeline

1. Catalog (or the debug UI) calls `POST /v1/embeddings` with a batch of `EmbeddingJob` payloads.
2. The API pushes each job onto a Redis Stream (`embeddings:jobs`).
3. One or more embedding workers (`python -m src.services.embedding_worker`) consume the stream, call the encoder client, and upsert/delete vectors inside Qdrant.
4. Any failures are written to a dead-letter stream (`embeddings:dlq`) for later inspection.

Key environment variables (see `.env.example.*`):

- `REDIS_URL`, `EMBEDDINGS_STREAM_KEY`, `EMBEDDINGS_CONSUMER_GROUP`, `DLQ_STREAM_KEY`
- `BATCH_MAX_MESSAGES`, `BATCH_MAX_WAIT_MS`, `WORKER_CONCURRENCY`
- `QDRANT_URL`, `QDRANT_COLLECTION`

The UI (`/ui`) now includes a form for posting embedding batches in addition to product registration and debug decoder/encoder tools.

## üß≠ Demo client

A lightweight HTML/JS client lives under `ui/`. Run `docker compose up` or `python -m http.server` inside `ui/` to exercise all routes, including the new embedding ingestion endpoint.
