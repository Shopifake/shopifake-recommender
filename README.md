docker build -t fastapi-template .
docker run -d -p 8000:8000 \
# Shopifake Recommender

FastAPI microservice powering the future RAG-based recommendation engine for Shopifake. This service stores embeddings alongside product metadata in Qdrant and provides vector similarity search to return top-k product IDs.

## ğŸš€ Features

- FastAPI 0.116.2 served through Gunicorn+Uvicorn workers
- Qdrant health monitoring to validate the vector store dependency
- Product registration endpoint with strict Pydantic schemas
- Redis-backed embedding ingestion API that pushes jobs onto a worker queue
- Streaming embedding worker that syncs vectors into Qdrant with optional deletes
- Debug-only decoder and encoder routes to validate LLM + embedding credentials
- End-to-end tests (pytest + httpx async fixtures)
- Ruff + Black enforced via CI workflows

## ğŸƒ Quick Start

```bash
cp .env.example.dev .env
# Fill in OPENAI_API_KEY plus the decoder (`OPENAI_MODEL`) and encoder (`OPENAI_EMBEDDING_MODEL`) names
pip install -r requirements.txt
uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload
python -m src.services.workers.embedding_worker  # runs the async embedding worker
```

Or spin up the full stack (app + Qdrant):

```bash
docker compose up -d --build
```

The compose file now starts FastAPI, Qdrant, Redis, the embedding worker, and the static UI container.

API surface:

- `GET /` â€“ Basic heartbeat
- `GET /health` â€“ Reports app status + Qdrant connectivity
- `POST /products/register` â€“ Primary contract used by the catalog service
- `POST /v1/embeddings` â€“ Asynchronously enqueue embedding jobs (returns 202)
- `POST /debug/decoder` â€“ Fire a completion against the configured decoder (non-prod)
- `POST /debug/encoder` â€“ Generate embeddings against the configured encoder (non-prod)

See autogenerated docs at http://localhost:8000/docs

## ğŸ“¦ Product registration contract

```json
{
  "product_id": "string",
  "site_id": "string",
  "name": "string",
  "description": "string",
  "images": ["https://..."],
  "categories": [{"id": "string", "site_id": "string", "name": "string"}],
  "sku": "string",
  "status": "PUBLISHED",
  "price": 199.99,
  "filters": [{"id": "string", "name": "string", "value": "string"}],
  "metadata": {}
}
```

The endpoint enqueues an embedding job for asynchronous processing and returns an acceptance response. The catalog service calls this route for every publish event.

## ğŸ§ª Development Commands

```bash
pytest
ruff check src tests
black src tests
```

## ğŸ—‚ï¸ Project highlights

```
src/
â”œâ”€â”€ main.py              # FastAPI setup and routing
â”œâ”€â”€ config.py            # Environment + Qdrant settings
â”œâ”€â”€ models/product.py    # Pydantic schemas for incoming payloads
â””â”€â”€ services/
    â”œâ”€â”€ clients/         # External API clients (OpenAI encoder/decoder)
    â”œâ”€â”€ core/            # Core business logic (currently empty)
    â”œâ”€â”€ queue/           # Redis stream and DLQ management
    â”œâ”€â”€ storage/         # Qdrant vector database operations
    â””â”€â”€ workers/         # Background embedding processing
```

`tests/` contains API-level tests that exercise the registration and embedding flows.

## ğŸ§ª Testing

### Unit Tests
Run fast unit tests with mocked dependencies:
```bash
pytest tests/ -m "not integration"
```

### Integration Tests
Run comprehensive integration tests with real Redis and Qdrant:
```bash
# Requires Docker
./run_integration_tests.sh
```

Or run manually:
```bash
# Start test services
docker-compose -f docker-compose.test.yml up -d

# Wait for services, then run tests
pytest tests/test_integration.py -v

# Cleanup
docker-compose -f docker-compose.test.yml down -v
```

Integration tests verify:
- Real Redis stream operations
- Real Qdrant vector storage
- End-to-end embedding pipeline
- Error handling with actual services

## ğŸ§µ Embedding pipeline

1. Catalog (or the debug UI) calls `POST /v1/embeddings` with a batch of `EmbeddingJob` payloads.
2. The API pushes each job onto a Redis Stream (`embeddings:jobs`).
3. One or more embedding workers (`python -m src.services.workers.embedding_worker`) consume the stream, call the encoder client, and upsert/delete vectors inside Qdrant.
4. Any failures are written to a dead-letter stream (`embeddings:dlq`) for later inspection.

Key environment variables (see `.env.example.*`):

- `REDIS_URL`, `EMBEDDINGS_STREAM_KEY`, `EMBEDDINGS_CONSUMER_GROUP`, `DLQ_STREAM_KEY`
- `BATCH_MAX_MESSAGES`, `BATCH_MAX_WAIT_MS`, `WORKER_CONCURRENCY`
- `QDRANT_URL`, `QDRANT_COLLECTION`

The UI (`/ui`) now includes a form for posting embedding batches in addition to product registration and debug decoder/encoder tools.

## ğŸ§­ Demo client

A lightweight HTML/JS client lives under `ui/`. Run `docker compose up` or `python -m http.server` inside `ui/` to exercise all routes, including the new embedding ingestion endpoint.
