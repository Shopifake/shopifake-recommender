"""Business logic that powers the chat endpoint."""

from __future__ import annotations

import logging
from typing import Any

from src.config import settings
from src.models.chat import (
    ChatHistoryEntry,
    ChatRecommendation,
    ChatRequest,
    ChatResultPayload,
)
from src.services.chat.result_store import ChatResultStore
from src.services.clients.decoder_client import DecoderClient
from src.services.clients.encoder_client import EncoderClient
from src.services.queue.embedding_queue import get_redis_client
from src.services.storage.qdrant_service import QdrantService, create_qdrant_service

logger = logging.getLogger(__name__)


class ChatOrchestrator:
    """Coordinates embeddings, vector search, and decoder generation."""

    def __init__(
        self,
        *,
        encoder: EncoderClient | None,
        decoder: DecoderClient | None,
        qdrant_service: QdrantService,
        result_store: ChatResultStore,
    ) -> None:
        self._encoder = encoder
        self._decoder = decoder
        self._qdrant_service = qdrant_service
        self._result_store = result_store

    async def initialize_request(self, request_id: str) -> None:
        await self._result_store.initialize(request_id)

    async def process_request(self, request_id: str, payload: ChatRequest) -> None:
        try:
            result = await self._execute(payload)
            await self._result_store.save_success(request_id, result)
        except Exception as exc:  # pylint: disable=broad-exception-caught
            logger.exception("Chat job %s failed", request_id)
            await self._result_store.save_failure(request_id, str(exc))

    async def _execute(self, payload: ChatRequest) -> ChatResultPayload:
        print(f"[ChatOrchestrator] Received chat request: {payload}")
        query = payload.query.strip()
        if not query:
            print("[ChatOrchestrator] Query text is empty, raising error.")
            raise ValueError("Query text cannot be empty")

        if self._needs_more_info(payload):
            print("[ChatOrchestrator] Needs more info from user.")
            result = ChatResultPayload(
                reply=self._build_more_info_reply(payload),
                decoder_satisfaction="need_more_info",
                recommendations=[],
            )
            print(f"[ChatOrchestrator] Returning: {result}")
            return result

        print("[ChatOrchestrator] Rewriting chat history and query for RAG search...")
        rag_query = await self._rewrite_as_rag_query(payload)
        print(f"[ChatOrchestrator] RAG query generated by decoder: '{rag_query}'")
        recommendations = await self._search_recommendations_with_rag_query(payload, rag_query)
        print(f"[ChatOrchestrator] Recommendations found: {recommendations}")
        status = "satisfied" if recommendations else "unsatisfied"
        print(f"[ChatOrchestrator] Decoder satisfaction status: {status}")
        if status == "satisfied":
            reply = await self._generate_reply(payload, recommendations)
            print(f"[ChatOrchestrator] Reply generated: '{reply}'")
        else:
            reply = "Sorry, I couldn't find any suitable products. Could you provide more details?"
            print(f"[ChatOrchestrator] Unsatisfied reply: '{reply}'")
            recommendations = []
        print(f"[ChatOrchestrator] Final result payload: reply='{reply}', status='{status}', recommendations={recommendations}")
        return ChatResultPayload(
            reply=reply,
            decoder_satisfaction=status,
            recommendations=recommendations,
        )

    async def _rewrite_as_rag_query(self, payload: ChatRequest) -> str:
        print(f"[ChatOrchestrator] Rewriting chat history and query for RAG search...")
        if self._decoder is None:
            print("[ChatOrchestrator] No decoder available, using raw query.")
            return payload.query.strip()
        history_lines = []
        for entry in payload.history:
            if getattr(entry, "role", None) == "rag":
                history_lines.append(f"rag: {entry.content.reply}")
            else:
                history_lines.append(f"user: {entry.content}")
        prompt = (
            "Rewrite the following chat history and latest question as a concise product search query for a recommender system.\n"
            f"History:\n{chr(10).join(history_lines)}\n"
            f"Latest question: {payload.query.strip()}\n"
            "Output only the search query, no explanation."
        )
        print(f"[ChatOrchestrator] Decoder prompt for RAG query: '{prompt}'")
        try:
            rag_query = await self._decoder.decode(prompt)
            print(f"[ChatOrchestrator] Decoder returned RAG query: '{rag_query.strip()}'")
            return rag_query.strip()
        except Exception as exc:
            logger.warning("Decoder error during RAG query rewrite: %s", exc)
            print(f"[ChatOrchestrator] Decoder error: {exc}. Using raw query.")
            return payload.query.strip()

    async def _search_recommendations_with_rag_query(
        self, payload: ChatRequest, rag_query: str
    ) -> list[ChatRecommendation]:
        print(f"[ChatOrchestrator] Searching recommendations for RAG query: '{rag_query}'")
        top_k = self._resolve_top_k(payload.params)
        text = rag_query
        if not text or self._encoder is None:
            print("[ChatOrchestrator] No text or encoder available, returning empty recommendations.")
            return []
        vector = await self._encode_text(text)
        print(f"[ChatOrchestrator] Encoded vector (first 5): {vector[:5]}")
        hits = await self._query_vector_store(vector, top_k)
        print(f"[ChatOrchestrator] Vector store hits: {hits}")
        candidates = self._convert_hits_to_recommendations(hits, payload.site_id, top_k)
        print(f"[ChatOrchestrator] Converted recommendations: {candidates}")
        return candidates

    @staticmethod
    def _needs_more_info(payload: ChatRequest) -> bool:
        tokens = payload.query.strip().split()
        has_rag_entry = any(
            getattr(entry, "role", None) == "rag" for entry in payload.history
        )

        if not has_rag_entry:
            # First interaction always asks for additional context.
            return True

        last_rag = next(
            (
                entry
                for entry in reversed(payload.history)
                if getattr(entry, "role", None) == "rag"
            ),
            None,
        )

        if last_rag and not getattr(last_rag.content, "recommendations", []):
            # Decoder previously asked for clarification; inspect follow-up detail.
            return len(tokens) <= 3

        return False

    @staticmethod
    def _build_more_info_reply(payload: ChatRequest) -> str:
        prompt = payload.query.strip().rstrip("?.! ") or "your request"
        return (
            "I'd love to help you find something special. Could you tell me "
            f"more about '{prompt}'? Who is it for and what do they enjoy?"
        )

    # Removed unsatisfied keyword logic and unsatisfied reply builder

    async def _search_recommendations(
        self,
        payload: ChatRequest,
    ) -> list[ChatRecommendation]:
        top_k = self._resolve_top_k(payload.params)
        text = self._compose_embedding_text(payload)
        if not text or self._encoder is None:
            return []

        vector = await self._encode_text(text)
        hits = await self._query_vector_store(vector, top_k)
        candidates = self._convert_hits_to_recommendations(hits, payload.site_id, top_k)
        return candidates

    async def _encode_text(self, text: str) -> list[float]:
        if self._encoder is None:
            raise RuntimeError("Encoder client is not configured")
        return await self._encoder.embed(text)

    async def _query_vector_store(
        self,
        vector: list[float],
        top_k: int,
    ) -> list[dict[str, Any]]:
        try:
            return await self._qdrant_service.search_similar(vector, limit=top_k)
        except Exception as exc:  # pylint: disable=broad-exception-caught
            logger.warning("Falling back to static catalog suggestions: %s", exc)
            return []

    @staticmethod
    def _convert_hits_to_recommendations(
        hits: list[dict[str, Any]],
        site_id: str,
        top_k: int,
    ) -> list[ChatRecommendation]:
        recommendations: list[ChatRecommendation] = []
        for hit in hits:
            payload_data: dict[str, Any] = hit.get("payload") or {}
            if payload_data.get("shop_id") not in (None, site_id):
                continue
            product_id = payload_data.get("product_id") or str(hit.get("id"))
            name = payload_data.get("name")
            if not name:
                metadata = payload_data.get("metadata") or {}
                name = metadata.get("name") or metadata.get("title")
            if not product_id or not name:
                continue
            recommendations.append(ChatRecommendation(product_id=product_id, name=name))
            if len(recommendations) >= top_k:
                break
        return recommendations

    # Removed fallback recommendations logic

    def _compose_embedding_text(self, payload: ChatRequest) -> str:
        pieces = [payload.query.strip()]
        last_user = self._extract_last_user_message(payload.history)
        if last_user:
            pieces.append(last_user)
        return " \n".join(piece for piece in pieces if piece).strip()

    @staticmethod
    def _extract_last_user_message(
        history: list[ChatHistoryEntry],
    ) -> str | None:
        for entry in reversed(history):
            if getattr(entry, "role", None) == "user":
                content = getattr(entry, "content", None)
                if isinstance(content, str):
                    return content
        return None

    async def _generate_reply(
        self,
        payload: ChatRequest,
        recommendations: list[ChatRecommendation],
    ) -> str:
        if self._decoder is None:
            return self._default_reply(payload.query, recommendations)

        prompt = self._build_decoder_prompt(payload, recommendations)
        try:
            response = await self._decoder.decode(prompt)
            if response:
                return response.strip()
        except Exception as exc:  # pylint: disable=broad-exception-caught
            logger.warning("Decoder error, falling back to template: %s", exc)

        return self._default_reply(payload.query, recommendations)

    @staticmethod
    def _default_reply(query: str, recommendations: list[ChatRecommendation]) -> str:
        names = ", ".join(rec.name for rec in recommendations)
        return (
            f"Here are some options related to '{query.strip()}': {names}. "
            "Let me know if you need variations or more details."
        )

    @staticmethod
    def _build_decoder_prompt(
        payload: ChatRequest,
        recommendations: list[ChatRecommendation],
    ) -> str:
        product_lines = "\n".join(
            f"- {rec.name} (id: {rec.product_id})" for rec in recommendations
        )
        history_lines = "\n".join(
            ChatOrchestrator._format_history_entry(entry) for entry in payload.history
        )
        return (
            "You are a concise shopping assistant. Use the customer's context and "
            "the product list to craft a short helpful reply.\n"
            f"Conversation so far:\n{history_lines}\n"
            f"Latest question: {payload.query}\n"
            f"Suggested products:\n{product_lines}\n"
            "Answer in under 60 words."
        )

    @staticmethod
    def _format_history_entry(entry: ChatHistoryEntry) -> str:
        if getattr(entry, "role", None) == "rag":
            return f"rag: {entry.content.reply}"
        return f"user: {entry.content}"

    @staticmethod
    def _resolve_top_k(params: dict[str, Any] | None) -> int:
        if not params:
            return settings.CHAT_DEFAULT_TOP_K
        try:
            top_k = int(params.get("top_k", settings.CHAT_DEFAULT_TOP_K))
        except (TypeError, ValueError):
            return settings.CHAT_DEFAULT_TOP_K
        return max(1, min(top_k, settings.RAG_MAX_TOP_K))


def create_chat_orchestrator(
    *,
    encoder: EncoderClient | None,
    decoder: DecoderClient | None,
    result_store: ChatResultStore | None = None,
) -> ChatOrchestrator:
    store = result_store
    if store is None:
        client = get_redis_client()
        store = ChatResultStore(client)
    qdrant = create_qdrant_service()
    return ChatOrchestrator(
        encoder=encoder,
        decoder=decoder,
        qdrant_service=qdrant,
        result_store=store,
    )
